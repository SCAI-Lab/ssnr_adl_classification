{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea93fa04",
   "metadata": {},
   "source": [
    "# Loading the features\n",
    "In the following cell, the features extracted from the windowed time-series are loaded into the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0c57df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Reading the tabular data'''\n",
    "import pickle\n",
    "import gzip\n",
    "import shutil\n",
    "import os\n",
    "import yaml\n",
    "import warnings\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def load_pickle_from_parts(parts_dir):\n",
    "    # Combine the parts into a single compressed file\n",
    "    combined_path = os.path.join(parts_dir, 'features_20s.gz')\n",
    "    with open(combined_path, 'wb') as combined_file:\n",
    "        part_num = 0\n",
    "        while True:\n",
    "            part_path = os.path.join(parts_dir, f'features_20s_part_{part_num:03d}')\n",
    "            if not os.path.exists(part_path):\n",
    "                break\n",
    "            with open(part_path, 'rb') as part_file:\n",
    "                shutil.copyfileobj(part_file, combined_file)\n",
    "            part_num += 1\n",
    "    \n",
    "    # Decompress the combined file and load the pickle data\n",
    "    with gzip.open(combined_path, 'rb') as f_in:\n",
    "        data = pickle.load(f_in)\n",
    "    \n",
    "    # Optionally remove the combined file after loading\n",
    "    os.remove(combined_path)\n",
    "    \n",
    "    return data\n",
    "\n",
    "# Example usage\n",
    "current_dir = os.getcwd()  # Use the current working directory\n",
    "parent_dir = os.path.dirname(current_dir)\n",
    "parts_dir = os.path.join(parent_dir, 'data')\n",
    "data_dict = load_pickle_from_parts(parts_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6a8ca83d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class | Activity         | Count\n",
      "--------------------------------\n",
      "0     | calmness         | 3646 \n",
      "1     | selfpropulsion   | 1760 \n",
      "2     | armraises        | 1022 \n",
      "3     | transfer         | 2018 \n",
      "4     | usingphone       | 1786 \n",
      "5     | talking          | 2524 \n",
      "6     | washhands        | 2246 \n",
      "7     | eating           | 1618 \n",
      "8     | assistedprop     | 1534 \n",
      "9     | usingcomputer    | 2494 \n",
      "10    | changingclothes  | 1126 \n",
      "11    | pressurerelief   | 1398 \n"
     ]
    }
   ],
   "source": [
    "'''Loading the data'''\n",
    "\n",
    "# Name of the devices to include in the pipeline\n",
    "devices = [\n",
    "    'corsano_wrist',\n",
    "    'cosinuss_ear',\n",
    "    'sensomative_back',\n",
    "    'sensomative_bottom',\n",
    "    'vivalink_patch',\n",
    "    'zurichmove_wheel'\n",
    "]\n",
    "n_devices = len(devices)\n",
    "\n",
    "# Load parameters from the yaml file\n",
    "# Get the current directory\n",
    "current_dir = os.getcwd()  # Use the current working directory\n",
    "# Get the parent directory\n",
    "parent_dir = os.path.abspath(os.path.join(current_dir, os.pardir))\n",
    "# Construct the path to the yaml file\n",
    "yaml_file_path = os.path.join(parent_dir, 'parameters.yaml')\n",
    "# Load the yaml file\n",
    "with open(yaml_file_path, 'r') as f:\n",
    "    params = yaml.safe_load(f)\n",
    "\n",
    "# Accessing the parameters\n",
    "seed_number = params['seed_number']\n",
    "upsample_freq = params['upsample_freq']\n",
    "activities_label_mapping = params['activities_label_mapping']\n",
    "\n",
    "'''Loading the data'''\n",
    "# Ignore FutureWarnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning, message='overflow encountered in cast')\n",
    "\n",
    "\n",
    "# Converting the dict data to a dataframe\n",
    "dfs = []\n",
    "subjects = []\n",
    "for i_subject, subject in enumerate(data_dict.keys()):\n",
    "    df1 = data_dict[subject]['corsano_wrist']\n",
    "    df2 = data_dict[subject]['cosinuss_ear']\n",
    "    df3 = data_dict[subject]['sensomative_back']\n",
    "    df4 = data_dict[subject]['sensomative_bottom']\n",
    "    df5 = data_dict[subject]['vivalink_patch']\n",
    "    df6 = data_dict[subject]['zurichmove_wheel']\n",
    "    df7 = data_dict[subject]['label']\n",
    "    df = pd.concat([df1, df2, df3, df4, df5, df6, df7], axis=1)\n",
    "    df['subject'] = i_subject\n",
    "    subjects.append(subject)\n",
    "    dfs.append(df)\n",
    "data_df = pd.concat(dfs)\n",
    "\n",
    "'''Converting the dataframe to float32 except for the 'label' and 'subject' columns'''\n",
    "data_df = data_df.astype('float32')\n",
    "data_df[['label', 'subject']] = data_df[['label', 'subject']].astype(int)\n",
    "\n",
    "'''Drop columns containing inf and nan values'''\n",
    "data_df = data_df.replace([np.inf, -np.inf], np.nan).dropna(axis=1, how='any')\n",
    "\n",
    "'''Updating the list of features for each device'''\n",
    "device_columns = []\n",
    "for device in devices:\n",
    "    columns = []\n",
    "    for column in data_df.columns:\n",
    "        if device in column:\n",
    "            columns.append(column)\n",
    "    device_columns.append(columns)\n",
    "\n",
    "# Convert the pandas df to cudf\n",
    "# data_df = cudf.DataFrame.from_pandas(data_df)\n",
    "\n",
    "# Reporting the data imbalance\n",
    "X = np.array(data_df.drop(['label', 'subject'], axis=1, inplace=False))\n",
    "y = np.array(data_df['label'])\n",
    "subjects = np.array(data_df['subject'])\n",
    "# Get unique classes and their counts\n",
    "classes, counts = np.unique(y, return_counts=True)\n",
    "# Create a report table\n",
    "report_table = np.vstack((classes, list(activities_label_mapping.keys()), counts)).T\n",
    "print(\"Class | Activity         | Count\")\n",
    "print(\"--------------------------------\")\n",
    "for row in report_table:\n",
    "    print(f\"{row[0]:<5} | {row[1]:<16} | {row[2]:<5}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssnr_2024",
   "language": "python",
   "name": "ssnr_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
