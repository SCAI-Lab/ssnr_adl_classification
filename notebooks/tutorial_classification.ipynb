{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba49768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.96      6903\n",
      "           1       0.92      0.96      0.94      7877\n",
      "           2       0.88      0.85      0.86      6990\n",
      "           3       0.86      0.85      0.86      7141\n",
      "           4       0.81      0.75      0.78      6824\n",
      "           5       0.84      0.83      0.83      6313\n",
      "           6       0.91      0.93      0.92      6876\n",
      "           7       0.91      0.92      0.91      7293\n",
      "           8       0.89      0.89      0.89      6825\n",
      "           9       0.78      0.81      0.79      6958\n",
      "\n",
      "    accuracy                           0.88     70000\n",
      "   macro avg       0.88      0.88      0.88     70000\n",
      "weighted avg       0.88      0.88      0.88     70000\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "      0     1     2     3     4     5     6     7     8     9\n",
      "0  6684     2    20     8     7    22   114    17    19    10\n",
      "1     2  7528   197    24     4    22     5    55    28    12\n",
      "2    42   358  5915    23    53    71    94   272   139    23\n",
      "3    15    31    83  6102    33   616    27    76   100    58\n",
      "4    23     8    38    40  5149    60    81    59   120  1246\n",
      "5    49    22    51   681    82  5221    81    24    51    51\n",
      "6   116     9    80    13    20    57  6395    12   158    16\n",
      "7    19   102   186    43   117     8     7  6675    45    91\n",
      "8    21    68   120    54   109    37   205    35  6100    76\n",
      "9    24    35    31   111   798    91    50   118    70  5630\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import KFold, RandomizedSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif, VarianceThreshold\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Load MNIST dataset\n",
    "mnist = fetch_openml('mnist_784', version=1)\n",
    "X = mnist.data\n",
    "y = mnist.target.astype(int)\n",
    "\n",
    "# Outer cross-validation\n",
    "outer_cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Inner cross-validation (used by RandomizedSearchCV)\n",
    "inner_cv = KFold(n_splits=3, shuffle=True, random_state=42)\n",
    "\n",
    "# Define the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('remove_constant', VarianceThreshold(threshold=0.0)),\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('selector', SelectKBest(score_func=f_classif)),\n",
    "    ('classifier', XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss'))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for RandomizedSearchCV\n",
    "param_grid = {\n",
    "    'selector__k': [50],\n",
    "    'classifier__n_estimators': [50, 100],\n",
    "    'classifier__max_depth': [3, 5, 7, 10],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'classifier__subsample': [0.6, 0.8, 1.0],\n",
    "    'classifier__colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'classifier__gamma': [0, 0.1, 0.2, 0.3]\n",
    "}\n",
    "\n",
    "outer_scores = []\n",
    "all_predictions = []\n",
    "all_true_labels = []\n",
    "\n",
    "# Perform nested cross-validation\n",
    "for train_index, test_index in outer_cv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    # RandomizedSearchCV for hyperparameter tuning\n",
    "    random_search = RandomizedSearchCV(estimator=pipeline, param_distributions=param_grid, cv=inner_cv, n_iter=50, random_state=42, refit=True, scoring='f1_micro', n_jobs=-1)\n",
    "    random_search.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the best model found by RandomizedSearchCV on the test set\n",
    "    best_model = random_search.best_estimator_\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Store results\n",
    "    all_predictions.extend(y_pred)\n",
    "    all_true_labels.extend(y_test)\n",
    "\n",
    "# Convert results to numpy arrays for analysis\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_true_labels, all_predictions)\n",
    "print('\\nClassification Report:')\n",
    "print(report)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predictions)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=range(10), columns=range(10))\n",
    "print('\\nConfusion Matrix:')\n",
    "print(conf_matrix_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "caa89901",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m confusion_matrix, classification_report, ConfusionMatrixDisplay\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Convert results to numpy arrays for analysis\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, ConfusionMatrixDisplay\n",
    "\n",
    "# Convert results to numpy arrays for analysis\n",
    "all_predictions = np.array(all_predictions)\n",
    "all_true_labels = np.array(all_true_labels)\n",
    "\n",
    "# Classification report\n",
    "report = classification_report(all_true_labels, all_predictions, output_dict=True)\n",
    "report_df = pd.DataFrame(report).transpose()\n",
    "print('\\nClassification Report:')\n",
    "print(report_df)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(all_true_labels, all_predictions)\n",
    "conf_matrix_df = pd.DataFrame(conf_matrix, index=range(10), columns=range(10))\n",
    "\n",
    "# Plot confusion matrix heatmap\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(conf_matrix_df, annot=True, fmt='d', cmap='Blues', cbar=False, xticklabels=range(10), yticklabels=range(10))\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.ylabel('True Label')\n",
    "plt.show()\n",
    "\n",
    "# Plot classification metrics\n",
    "metrics = ['precision', 'recall', 'f1-score']\n",
    "report_df = report_df[:-3]  # Remove the last three rows: 'accuracy', 'macro avg', 'weighted avg'\n",
    "\n",
    "fig, ax = plt.subplots(1, 3, figsize=(20, 5))\n",
    "\n",
    "for idx, metric in enumerate(metrics):\n",
    "    sns.barplot(x=report_df.index, y=report_df[metric], ax=ax[idx])\n",
    "    ax[idx].set_title(f'{metric.capitalize()} by Class')\n",
    "    ax[idx].set_xlabel('Class')\n",
    "    ax[idx].set_ylabel(metric.capitalize())\n",
    "    ax[idx].set_ylim(0, 1)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ssnr_2024",
   "language": "python",
   "name": "ssnr_2024"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
